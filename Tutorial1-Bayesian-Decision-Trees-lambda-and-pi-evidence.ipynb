{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Bayesian Decision Trees, $\\lambda$ and $\\pi$ evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Link matrices\n",
    "P_DE = np.array([[0.4, 0.33, 0.29],[0.4,0.33,0.14],[0.2,0.34,0.14],[0,0,0.43]])\n",
    "P_SE = np.array([[0,0.33,0.14],[0.6,0,0.14],[0.4,0.34,0],[0,0.33,0.14],[0,0,0.14],[0,0,0.14],[0,0,0.28]])\n",
    "P_FC = np.array([[0,0.3],[0.125,0],[0.125,0.14],[0.25,0.14],[0.125,0],[0.125,0],[0, 0.14],[0.125,0.14],[0, 0.14],[0.125,0]])\n",
    "P_EC = np.array([[0.5,0.14],[0.25,0.14],[0.25,0.72]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `1.` An image is processed, and the following data extracted: $[s_1, d_2, f_3]$. Calculate the $\\lambda$ evidence that is propagated and the probability distributions over C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_s1 = 1\n",
    "lambda_d2 = 1\n",
    "lambda_f3 = 1\n",
    "\n",
    "lambda_e1 = (lambda_s1*P_SE[0,0])*(lambda_d2*P_DE[1,0])\n",
    "lambda_e2 = (lambda_s1*P_SE[0,1])*(lambda_d2*P_DE[1,1])\n",
    "lambda_e3 = (lambda_s1*P_SE[0,2])*(lambda_d2*P_DE[1,2])\n",
    "\n",
    "lambda_c1 = (lambda_e1*P_EC[0,0]+lambda_e2*P_EC[1,0]+lambda_e3*P_EC[2,0])*(lambda_f3*P_FC[2,0])\n",
    "lambda_c2 = (lambda_e1*P_EC[0,1]+lambda_e2*P_EC[1,1]+lambda_e3*P_EC[2,1])*(lambda_f3*P_FC[3,1])\n",
    "\n",
    "probability_c1 = lambda_c1/(lambda_c1+lambda_c2)\n",
    "probability_c2 = lambda_c2/(lambda_c1+lambda_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda e1 =  0.0\n",
      "lambda e2 =  0.1089\n",
      "lambda e3 =  0.0196\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda e1 = \", lambda_e1)\n",
    "print(\"lambda e2 = \", lambda_e2)\n",
    "print(\"lambda e3 = \", lambda_e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda c1 =  0.004015625\n",
      "lambda c2 =  0.00411012\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda c1 = \",lambda_c1)\n",
    "print(\"lambda c2 = \",lambda_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of c1 = 0.494\n",
      "probability of c2 = 0.506\n"
     ]
    }
   ],
   "source": [
    "print(\"probability of c1 = %.3f\" %probability_c1)\n",
    "print(\"probability of c2 = %.3f\" %probability_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2.`The same image is processed in monochrome. Thus there is no information for $F$. Re-calculate the probabilities of $C$ for the cases given in `question 1`. Remember that the data is $[s_1, d_2]$, and since nothing is known about $F$, the $\\lambda$ value for every state of $F$ is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_c1 = 0.032\n",
      "lambda_c2 = 0.029\n",
      "probability of c1 = 0.52\n",
      "probability of c2 = 0.48\n"
     ]
    }
   ],
   "source": [
    "lambda_s1 = 1\n",
    "lambda_d2 = 1\n",
    "# Since no evidence from F we know that lambda_F_c1 = lambda_F_c2 so we may just consider the lambda evidence from E\n",
    "lambda_f = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "# lambda_e1, lambda_e2, lambda_e3 stay the same\n",
    "# First column of a P(F|C) matrix is P_FC[:,0]\n",
    "\n",
    "lambda_c1 = (lambda_e1*P_EC[0,0]+lambda_e2*P_EC[1,0]+lambda_e3*P_EC[2,0])*(np.sum(lambda_f*P_FC[:,0]))\n",
    "lambda_c2 = (lambda_e1*P_EC[0,1]+lambda_e2*P_EC[1,1]+lambda_e3*P_EC[2,1])*(np.sum(lambda_f*P_FC[:,1]))\n",
    "\n",
    "probability_c1 = lambda_c1/(lambda_c1+lambda_c2)\n",
    "probability_c2 = lambda_c2/(lambda_c1+lambda_c2)\n",
    "\n",
    "print(\"lambda_c1 = %.3f\" %lambda_c1)\n",
    "print(\"lambda_c2 = %.3f\" %lambda_c2)\n",
    "\n",
    "print(\"probability of c1 = %.2f\" %probability_c1)\n",
    "print(\"probability of c2 = %.2f\" %probability_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `3.` Doubt is expressed about the accuracy of the computer vision algorithms. Thus instead $S$ and $D$ are instantiated with virtual evidence as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of c1 = 0.57\n",
      "probability of c2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "lambda_s = np.array([0.8, 0.2, 0, 0, 0, 0, 0])\n",
    "lambda_d = np.array([0.3, 0.4, 0.3, 0])\n",
    "lambda_f = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "lambda_e1 = np.sum(lambda_s*P_SE[:,0])*np.sum(lambda_d*P_DE[:,0])\n",
    "lambda_e2 = np.sum(lambda_s*P_SE[:,1])*np.sum(lambda_d*P_DE[:,1])\n",
    "lambda_e3 = np.sum(lambda_s*P_SE[:,2])*np.sum(lambda_d*P_DE[:,2])\n",
    "\n",
    "lambda_c1 = (lambda_e1*P_EC[0,0]+lambda_e2*P_EC[1,0]+lambda_e3*P_EC[2,0])*(np.sum(lambda_f*P_FC[:,0]))\n",
    "lambda_c2 = (lambda_e1*P_EC[0,1]+lambda_e2*P_EC[1,1]+lambda_e3*P_EC[2,1])*(np.sum(lambda_f*P_FC[:,1]))\n",
    "\n",
    "probability_c1 = lambda_c1/(lambda_c1+lambda_c2)\n",
    "probability_c2 = lambda_c2/(lambda_c1+lambda_c2)\n",
    "\n",
    "print(\"probability of c1 = %.2f\" %probability_c1)\n",
    "print(\"probability of c2 = %.2f\" %probability_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `4.` Given the evidence for $C$ in part 3, calculate the probability distribution over $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12862742]\n",
      " [ 0.07140524]\n",
      " [ 0.13143137]\n",
      " [ 0.20283661]\n",
      " [ 0.07140524]\n",
      " [ 0.07140524]\n",
      " [ 0.06002613]\n",
      " [ 0.13143137]\n",
      " [ 0.06002613]\n",
      " [ 0.07140524]]\n"
     ]
    }
   ],
   "source": [
    "# prior probability of C\n",
    "probability_c = np.array([[probability_c1, probability_c2]])\n",
    "\n",
    "# pi evidence for C excluding any evidence from F\n",
    "pi_F_C = np.array(probability_c)\n",
    "\n",
    "# pi evidence to F from C\n",
    "pi_F = P_FC.dot(pi_F_C.transpose())\n",
    "\n",
    "# probability of F\n",
    "probability_F = pi_F/np.sum(pi_F)\n",
    "\n",
    "print(probability_F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
